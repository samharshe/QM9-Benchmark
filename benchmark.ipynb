{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# benchmark.\n",
    "building a basic $E(3)$-equivariant message-passing graph neural network to predict internal energy at 0K on QM9 to make sure I am comfortable with this stuff in practice as well as in theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to-do:  \n",
    "[] build a DataLoader to make MBGD easier.  \n",
    "    [] build custom Graph class if necessary.  \n",
    "[] learn how you're supposed to keep track of loss through training.  \n",
    "[] separate training, test sets.  \n",
    "[] figure out how to load in all of QM9 without crashing kernel.\n",
    "[] build a version of the model only message-passing between nodes within a certain distance of each other.  \n",
    "[] build a version of the model with edge attribute of the square of the distance between nodes, which makes more sense physically.  \n",
    "[] figure out how to save trained model.\n",
    "[] in general get better at memory management and whatnot and learn how this thing works at runtime to reduce the frequency at which my computer crashes (once per 15 minutes approximately at the moment: lots of room for improvement)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import everything.\n",
    "no PyTorch_Geometric. only vanilla PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from itertools import product\n",
    "from typing import List, Any, Set\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import Tensor, LongTensor\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model components.  \n",
    "the EVGNN has everything.  \n",
    "EVMPLayer is message-passing.  \n",
    "RowWiseFCL is just a FCL that operates on a tensor of an arbitrary row-length, since we want to be able to operate atom-wise on a molecule of an arbitrary number of atoms.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EVGNN(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(EVGNN, self).__init__()\n",
    "        # size of the embedding space\n",
    "        self.embed_dim = 32\n",
    "        \n",
    "        self.embedding = nn.Embedding(118, self.embed_dim)\n",
    "        self.mp1 = EVMPLayer(self.embed_dim)\n",
    "        self.mp2 = EVMPLayer(self.embed_dim)\n",
    "        self.prediction1 = RowWiseFCL(self.embed_dim, 8) \n",
    "        self.prediction2 = RowWiseFCL(8, 1) \n",
    "\n",
    "    def forward(self, data = Data) -> float:\n",
    "        # print('IN MODEL\\n', data)\n",
    "        x = self.embedding(data.x)\n",
    "        # print('EMBEDDING\\n', x)\n",
    "        x = self.mp1(x, data.e)\n",
    "        x = F.normalize(x, p=1, dim=0)\n",
    "        # print('MESSAGE PASSING 1\\n', x)\n",
    "        x = self.mp2(x, data.e)\n",
    "        x = F.normalize(x, p=1, dim=0)\n",
    "        # print('MESSAGE PASSING 2\\n', x)\n",
    "        x = self.prediction1(x)\n",
    "        # print('PREDICTION 1\\n', x)\n",
    "        x = self.prediction2(x)\n",
    "        # print('PREDICTION 2\\n', x)\n",
    "        U_hat = torch.sum(x)\n",
    "        # print('FINAL PREDICTION\\n', U_hat)\n",
    "        return U_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EVMPLayer(nn.Module):\n",
    "    def __init__(self, embed_dim: int) -> None:\n",
    "        super(EVMPLayer, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.act = nn.Tanh()\n",
    "        message_input_size = 2 * embed_dim + 1\n",
    "        \n",
    "        # take in a message tensor of size 2 * embed_dim + 1 and get out a new h_i of size embed_dim\n",
    "        self.message_mlp = nn.Sequential(nn.Linear(message_input_size, embed_dim), self.act)\n",
    "        \n",
    "        # take in a message tensor of size embed_dim and an original h_i of size embed_dim and get out a new h_i of size embed_dim\n",
    "        self.update_node_mlp = nn.Sequential(nn.Linear(2 * embed_dim, embed_dim), self.act)\n",
    "                \n",
    "    def make_message(self, source_tensor: int, target_tensor: int, distance: float) -> Tensor:\n",
    "        combined_tensor = torch.cat((source_tensor.view(-1), target_tensor.view(-1), torch.Tensor([distance])))\n",
    "        return self.message_mlp(combined_tensor)\n",
    "    \n",
    "    def update_node(self, node_tensor: Tensor, message_tensor: Tensor) -> Tensor:\n",
    "        combined_tensor = torch.cat((node_tensor, message_tensor)).view(1,-1)\n",
    "        return self.update_node_mlp(combined_tensor)\n",
    "    \n",
    "    def forward(self, embed_tensor: Tensor, edge_distances: Tensor) -> Tensor:\n",
    "        new_embed_tensor = torch.zeros_like(embed_tensor)\n",
    "        # for each molecule in the dataset\n",
    "        for ix, source in enumerate(embed_tensor):\n",
    "            # create a tensor that tracks the sum of the messages\n",
    "            message_sum = torch.zeros_like(source)\n",
    "            # for each other molecule in the dataset\n",
    "            for jx, target in enumerate(embed_tensor):\n",
    "                if ix != jx:\n",
    "                    # add the message tensor between them to the sum tensor\n",
    "                    message_sum += self.make_message(source, target, edge_distances[ix,jx].item())\n",
    "            # update the tensor that keeps track of all molecule embeddings by making its row ix the new embedding of the molecule\n",
    "            new_embed_tensor[ix] = self.update_node(source, message_sum)\n",
    "        \n",
    "        return new_embed_tensor\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RowWiseFCL(nn.Module): \n",
    "    def __init__(self, in_dim: int, out_dim: int) -> None: \n",
    "        super(RowWiseFCL, self).__init__() \n",
    "        self.out_dim = out_dim\n",
    "        self.row_layer = nn.Sequential(nn.Linear(in_dim, out_dim), nn.Tanh())\n",
    "      \n",
    "    def forward(self, embed_tensor: Tensor) -> Tensor:\n",
    "        new_embed_tensor = torch.zeros(embed_tensor.size(0), self.out_dim)\n",
    "        for ix, row in enumerate(embed_tensor):\n",
    "            new_embed_tensor[ix] = self.row_layer(row)\n",
    "        return new_embed_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MoleculesDataset class.  \n",
    "pretty stupid. just a wrapper for Data objects. the point was to be able to pass this into a DataLoader, but the PyTorch_Geometric DataLoader seems more trouble than it's worth, so as mentioned above, this will probably be deprecated soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoleculesDataset(Dataset):\n",
    "    def __init__(self, data: List[Data]) -> None:\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Data:\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph class.\n",
    "the PyTorch Data objects are really bothering me, so I'm making my own version of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnectedData():\n",
    "    def __init__(self, x: Tensor, pos: Tensor, y: Tensor) -> None:\n",
    "        self.x = x\n",
    "        self.pos = pos\n",
    "        self.y = y\n",
    "        self.e = make_edge_distances(pos)\n",
    "        # self.e_2 = torch.square(self.e)\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return x.size(0)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"x: {x.size()} | pos: {self.pos.size()} | e: {self.e.size()} | y = {self.y}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "    def __init__(self, x: Tensor, pos: Tensor, connectivity: List[Set[int]], y: Tensor) -> None:\n",
    "        self.x = x\n",
    "        self.pos = pos\n",
    "        self.y = y\n",
    "        self.e = torch.zeros(x.size(0), x.size(0))\n",
    "        self.connectivity = connectivity\n",
    "        for pair in connectivity:\n",
    "            a, b = pair\n",
    "            self.e[a][b] = self.e[b][a] = compute_distance(pos[a], pos[b])\n",
    "        # self.e_2 = torch.square(self.e)\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return x.size(0)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"x: {x.size()} | pos: {self.pos.size()} | e: {self.e.size()} | y = {self.y}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper functions.\n",
    "all self-explanitory. makes it simpler to build the Data items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance(pos1: Tensor, pos2: Tensor) -> float:\n",
    "    return torch.sum(torch.pow(torch.sub(pos1, pos2), 2)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_edge_distances(positions: Tensor) -> Tensor:\n",
    "    edge_distances = torch.zeros(positions.size(0), positions.size(0))\n",
    "    for ix, source_position in enumerate(positions):\n",
    "        for jx, target_position in enumerate(positions):\n",
    "            edge_distances[ix][jx] = compute_distance(source_position, target_position)\n",
    "    return edge_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build the dataset from saved CSVs.  \n",
    "makes custom Data objects.  \n",
    "$x$ is atomic numbers.  \n",
    "$pos$ is positions.\n",
    "full connectivity.  \n",
    "$edge\\_distances$ is a matrix containing the distance from atom $i$ to atom $j$. it si saved with the Data instance so this can all be calculated up front and not waste computatino each time through message passing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_head = 'baby_QM9/raw/'\n",
    "\n",
    "node_features_df = pd.read_csv(path_head + 'node_attributes.txt', header=None)\n",
    "node_features = torch.tensor(node_features_df.values)\n",
    "\n",
    "graph_features_df = pd.read_csv(path_head + 'Y.txt', header=None)\n",
    "graph_features = torch.tensor(graph_features_df.values)\n",
    "\n",
    "atomic_numbers = node_features[:,5].long()\n",
    "\n",
    "positions = node_features[:,-3:]\n",
    "\n",
    "internal_energies = graph_features[:,7]\n",
    "# divide by the largest negative value in the dataset so that all values are between 0 and 1\n",
    "internal_energies_normalized = torch.div(internal_energies, torch.min(internal_energies))\n",
    "internal_energies_normalized_list = internal_energies_normalized.tolist()\n",
    "\n",
    "new_graph_node_indices = [0]\n",
    "node_indicators_df = pd.read_csv(path_head + 'graph_indicator.txt', header=None)\n",
    "node_indicators = node_indicators_df.values.tolist()\n",
    "for ix in range(len((node_indicators)))[1:]:\n",
    "    if node_indicators[ix] != node_indicators[ix-1]:\n",
    "        new_graph_node_indices.append(ix)\n",
    "new_graph_node_indices.append(len(node_indicators))\n",
    "\n",
    "molecules_list = []\n",
    "for start, end in zip(new_graph_node_indices, new_graph_node_indices[1:]):\n",
    "    x = atomic_numbers.clone()[start:end].view(-1, 1)\n",
    "    y = torch.Tensor([internal_energies_normalized_list.pop(0)])\n",
    "    pos = positions.clone()[start:end]\n",
    "    molecule = FullyConnectedData(x=x, pos=pos, y=y)\n",
    "    molecules_list.append(molecule)\n",
    "    \n",
    "molecules_dataset = MoleculesDataset(molecules_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build model and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/GDL/lib/python3.12/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0 COMPLETE | MEAN LOSS 8.634395897388458e-05\n",
      "EPOCH 1 COMPLETE | MEAN LOSS 0.0036683350801467894\n",
      "EPOCH 2 COMPLETE | MEAN LOSS 0.0005930579826235771\n",
      "EPOCH 3 COMPLETE | MEAN LOSS 0.00047380849719047546\n",
      "EPOCH 4 COMPLETE | MEAN LOSS 0.0013233894109725953\n",
      "EPOCH 5 COMPLETE | MEAN LOSS 0.0009075973927974701\n",
      "EPOCH 6 COMPLETE | MEAN LOSS 7.590647437609732e-06\n",
      "EPOCH 7 COMPLETE | MEAN LOSS 0.00012346326373517514\n",
      "EPOCH 8 COMPLETE | MEAN LOSS 0.0003356170654296875\n",
      "EPOCH 9 COMPLETE | MEAN LOSS 0.0003246345743536949\n",
      "EPOCH 10 COMPLETE | MEAN LOSS 0.0001493784226477146\n",
      "EPOCH 11 COMPLETE | MEAN LOSS 1.2152316048741341e-05\n",
      "EPOCH 12 COMPLETE | MEAN LOSS 2.7447473257780075e-05\n",
      "EPOCH 13 COMPLETE | MEAN LOSS 0.00013055051676928996\n",
      "EPOCH 14 COMPLETE | MEAN LOSS 1.4915454667061567e-05\n",
      "EPOCH 15 COMPLETE | MEAN LOSS 2.078009070828557e-05\n",
      "EPOCH 16 COMPLETE | MEAN LOSS 3.718615334946662e-06\n",
      "EPOCH 17 COMPLETE | MEAN LOSS 7.434257713612169e-07\n",
      "EPOCH 18 COMPLETE | MEAN LOSS 1.3510655662685168e-07\n",
      "EPOCH 19 COMPLETE | MEAN LOSS 1.8781682592816652e-06\n",
      "EPOCH 20 COMPLETE | MEAN LOSS 3.5117470542900266e-06\n",
      "EPOCH 21 COMPLETE | MEAN LOSS 3.158420149702579e-06\n",
      "EPOCH 22 COMPLETE | MEAN LOSS 1.3559848594013603e-06\n",
      "EPOCH 23 COMPLETE | MEAN LOSS 6.989645953581203e-08\n",
      "EPOCH 24 COMPLETE | MEAN LOSS 3.960821049986407e-07\n",
      "EPOCH 25 COMPLETE | MEAN LOSS 1.5616179734934122e-06\n",
      "EPOCH 26 COMPLETE | MEAN LOSS 2.054612268693745e-06\n",
      "EPOCH 27 COMPLETE | MEAN LOSS 1.3512450095731766e-06\n",
      "EPOCH 28 COMPLETE | MEAN LOSS 3.118573295068927e-07\n",
      "EPOCH 29 COMPLETE | MEAN LOSS 2.683174898265861e-08\n",
      "EPOCH 30 COMPLETE | MEAN LOSS 5.908725870540366e-07\n",
      "EPOCH 31 COMPLETE | MEAN LOSS 1.1549802002264186e-06\n",
      "EPOCH 32 COMPLETE | MEAN LOSS 1.0177699732594191e-06\n",
      "EPOCH 33 COMPLETE | MEAN LOSS 3.8827343814773483e-07\n",
      "EPOCH 34 COMPLETE | MEAN LOSS 4.821831680601463e-09\n",
      "EPOCH 35 COMPLETE | MEAN LOSS 2.0841271179961042e-07\n",
      "EPOCH 36 COMPLETE | MEAN LOSS 6.127567758085206e-07\n",
      "EPOCH 37 COMPLETE | MEAN LOSS 6.669013237114996e-07\n",
      "EPOCH 38 COMPLETE | MEAN LOSS 3.256214768043719e-07\n",
      "EPOCH 39 COMPLETE | MEAN LOSS 2.2969443307374602e-08\n",
      "EPOCH 40 COMPLETE | MEAN LOSS 7.948954589664935e-08\n",
      "EPOCH 41 COMPLETE | MEAN LOSS 3.335067958687432e-07\n",
      "EPOCH 42 COMPLETE | MEAN LOSS 4.124531551497057e-07\n",
      "EPOCH 43 COMPLETE | MEAN LOSS 2.227715594926849e-07\n",
      "EPOCH 44 COMPLETE | MEAN LOSS 2.1710304736188844e-08\n",
      "EPOCH 45 COMPLETE | MEAN LOSS 4.0477220863976984e-08\n",
      "EPOCH 46 COMPLETE | MEAN LOSS 1.971778692677617e-07\n",
      "EPOCH 47 COMPLETE | MEAN LOSS 2.5025588911375963e-07\n",
      "EPOCH 48 COMPLETE | MEAN LOSS 1.327323025179794e-07\n",
      "EPOCH 49 COMPLETE | MEAN LOSS 1.0676599231373984e-08\n",
      "EPOCH 50 COMPLETE | MEAN LOSS 2.999021262439783e-08\n",
      "EPOCH 51 COMPLETE | MEAN LOSS 1.2798510397260542e-07\n",
      "EPOCH 52 COMPLETE | MEAN LOSS 1.4938137610442936e-07\n",
      "EPOCH 53 COMPLETE | MEAN LOSS 6.822750037827063e-08\n",
      "EPOCH 54 COMPLETE | MEAN LOSS 1.955996253855119e-09\n",
      "EPOCH 55 COMPLETE | MEAN LOSS 2.9029811230429915e-08\n",
      "EPOCH 56 COMPLETE | MEAN LOSS 8.803353921393863e-08\n",
      "EPOCH 57 COMPLETE | MEAN LOSS 8.474015885440166e-08\n",
      "EPOCH 58 COMPLETE | MEAN LOSS 2.7892581329069798e-08\n",
      "EPOCH 59 COMPLETE | MEAN LOSS 2.0939587841439787e-10\n",
      "EPOCH 60 COMPLETE | MEAN LOSS 2.998608351845178e-08\n",
      "EPOCH 61 COMPLETE | MEAN LOSS 5.981000413157744e-08\n",
      "EPOCH 62 COMPLETE | MEAN LOSS 4.242479008098599e-08\n",
      "EPOCH 63 COMPLETE | MEAN LOSS 6.923337423359044e-09\n",
      "EPOCH 64 COMPLETE | MEAN LOSS 4.079294910752651e-09\n",
      "EPOCH 65 COMPLETE | MEAN LOSS 2.8773445137630915e-08\n",
      "EPOCH 66 COMPLETE | MEAN LOSS 3.670908427011455e-08\n",
      "EPOCH 67 COMPLETE | MEAN LOSS 1.6221765690715984e-08\n",
      "EPOCH 68 COMPLETE | MEAN LOSS 1.6281413550700564e-10\n",
      "EPOCH 69 COMPLETE | MEAN LOSS 9.380229926136963e-09\n",
      "EPOCH 70 COMPLETE | MEAN LOSS 2.3323555069509894e-08\n",
      "EPOCH 71 COMPLETE | MEAN LOSS 1.8028003978542984e-08\n",
      "EPOCH 72 COMPLETE | MEAN LOSS 3.175012750489259e-09\n",
      "EPOCH 73 COMPLETE | MEAN LOSS 1.6103227551411692e-09\n",
      "EPOCH 74 COMPLETE | MEAN LOSS 1.1885657613674994e-08\n",
      "EPOCH 75 COMPLETE | MEAN LOSS 1.457482198929938e-08\n",
      "EPOCH 76 COMPLETE | MEAN LOSS 5.5929382369868105e-09\n",
      "EPOCH 77 COMPLETE | MEAN LOSS 4.395703800952333e-12\n",
      "EPOCH 78 COMPLETE | MEAN LOSS 5.007772188037052e-09\n",
      "EPOCH 79 COMPLETE | MEAN LOSS 9.832956493482926e-09\n",
      "EPOCH 80 COMPLETE | MEAN LOSS 5.955919277766952e-09\n",
      "EPOCH 81 COMPLETE | MEAN LOSS 3.9638585747070464e-10\n",
      "EPOCH 82 COMPLETE | MEAN LOSS 1.735611192543729e-09\n",
      "EPOCH 83 COMPLETE | MEAN LOSS 5.928581003900035e-09\n",
      "EPOCH 84 COMPLETE | MEAN LOSS 5.043054329689767e-09\n",
      "EPOCH 85 COMPLETE | MEAN LOSS 9.217973939712465e-10\n",
      "EPOCH 86 COMPLETE | MEAN LOSS 4.669775677257348e-10\n",
      "EPOCH 87 COMPLETE | MEAN LOSS 3.342059073929704e-09\n",
      "EPOCH 88 COMPLETE | MEAN LOSS 3.766878649003047e-09\n",
      "EPOCH 89 COMPLETE | MEAN LOSS 1.1154245527222883e-09\n",
      "EPOCH 90 COMPLETE | MEAN LOSS 8.111275207056678e-11\n",
      "EPOCH 91 COMPLETE | MEAN LOSS 1.8281946267961757e-09\n",
      "EPOCH 92 COMPLETE | MEAN LOSS 2.621022190396616e-09\n",
      "EPOCH 93 COMPLETE | MEAN LOSS 1.0370267489179242e-09\n",
      "EPOCH 94 COMPLETE | MEAN LOSS 3.3374991659229636e-12\n",
      "EPOCH 95 COMPLETE | MEAN LOSS 1.0024814400821924e-09\n",
      "EPOCH 96 COMPLETE | MEAN LOSS 1.7571569799201824e-09\n",
      "EPOCH 97 COMPLETE | MEAN LOSS 8.362902548242346e-10\n",
      "EPOCH 98 COMPLETE | MEAN LOSS 2.8604341117954846e-12\n",
      "EPOCH 99 COMPLETE | MEAN LOSS 5.693582849630729e-10\n",
      "EPOCH 100 COMPLETE | MEAN LOSS 1.1613752093353469e-09\n",
      "EPOCH 101 COMPLETE | MEAN LOSS 6.158533949474077e-10\n",
      "EPOCH 102 COMPLETE | MEAN LOSS 8.391367600779631e-12\n",
      "EPOCH 103 COMPLETE | MEAN LOSS 3.433458672930101e-10\n",
      "EPOCH 104 COMPLETE | MEAN LOSS 7.66534355989279e-10\n",
      "EPOCH 105 COMPLETE | MEAN LOSS 4.252552088246375e-10\n",
      "EPOCH 106 COMPLETE | MEAN LOSS 7.56664952916708e-12\n",
      "EPOCH 107 COMPLETE | MEAN LOSS 2.2382451447811036e-10\n",
      "EPOCH 108 COMPLETE | MEAN LOSS 5.088352850179944e-10\n",
      "EPOCH 109 COMPLETE | MEAN LOSS 2.7813499059448075e-10\n",
      "EPOCH 110 COMPLETE | MEAN LOSS 3.5757197203167836e-12\n",
      "EPOCH 111 COMPLETE | MEAN LOSS 1.578706587679335e-10\n",
      "EPOCH 112 COMPLETE | MEAN LOSS 3.398207226723571e-10\n",
      "EPOCH 113 COMPLETE | MEAN LOSS 1.7202950175487786e-10\n",
      "EPOCH 114 COMPLETE | MEAN LOSS 5.115907697472721e-13\n",
      "EPOCH 115 COMPLETE | MEAN LOSS 1.1920448628188752e-10\n",
      "EPOCH 116 COMPLETE | MEAN LOSS 2.2637316021700825e-10\n",
      "EPOCH 117 COMPLETE | MEAN LOSS 9.928939448400342e-11\n",
      "EPOCH 118 COMPLETE | MEAN LOSS 2.6736168834418093e-13\n",
      "EPOCH 119 COMPLETE | MEAN LOSS 9.375612286532941e-11\n",
      "EPOCH 120 COMPLETE | MEAN LOSS 1.491207690662577e-10\n",
      "EPOCH 121 COMPLETE | MEAN LOSS 5.182201334719139e-11\n",
      "EPOCH 122 COMPLETE | MEAN LOSS 2.7259616786068362e-12\n",
      "EPOCH 123 COMPLETE | MEAN LOSS 7.482464425834223e-11\n",
      "EPOCH 124 COMPLETE | MEAN LOSS 9.503012599054728e-11\n",
      "EPOCH 125 COMPLETE | MEAN LOSS 2.3122679326803562e-11\n",
      "EPOCH 126 COMPLETE | MEAN LOSS 6.676339481259675e-12\n",
      "EPOCH 127 COMPLETE | MEAN LOSS 5.907488720424681e-11\n",
      "EPOCH 128 COMPLETE | MEAN LOSS 5.7166440470268755e-11\n",
      "EPOCH 129 COMPLETE | MEAN LOSS 7.714930916336016e-12\n",
      "EPOCH 130 COMPLETE | MEAN LOSS 1.0659209070951192e-11\n",
      "EPOCH 131 COMPLETE | MEAN LOSS 4.484420834671709e-11\n",
      "EPOCH 132 COMPLETE | MEAN LOSS 3.142518245624615e-11\n",
      "EPOCH 133 COMPLETE | MEAN LOSS 1.2028067430946976e-12\n",
      "EPOCH 134 COMPLETE | MEAN LOSS 1.3437251311643195e-11\n",
      "EPOCH 135 COMPLETE | MEAN LOSS 3.192837993992726e-11\n",
      "EPOCH 136 COMPLETE | MEAN LOSS 1.4814569571086622e-11\n",
      "EPOCH 137 COMPLETE | MEAN LOSS 5.473177466797097e-14\n",
      "EPOCH 138 COMPLETE | MEAN LOSS 1.4190391084412112e-11\n",
      "EPOCH 139 COMPLETE | MEAN LOSS 2.0655699373151037e-11\n",
      "EPOCH 140 COMPLETE | MEAN LOSS 5.32774047101725e-12\n",
      "EPOCH 141 COMPLETE | MEAN LOSS 1.4532397507593942e-12\n",
      "EPOCH 142 COMPLETE | MEAN LOSS 1.2928700332537347e-11\n",
      "EPOCH 143 COMPLETE | MEAN LOSS 1.1603598082388089e-11\n",
      "EPOCH 144 COMPLETE | MEAN LOSS 1.0086953494692353e-12\n",
      "EPOCH 145 COMPLETE | MEAN LOSS 3.3157565582087046e-12\n",
      "EPOCH 146 COMPLETE | MEAN LOSS 1.0111813608659758e-11\n",
      "EPOCH 147 COMPLETE | MEAN LOSS 5.252340784522857e-12\n",
      "EPOCH 148 COMPLETE | MEAN LOSS 1.1746159600534156e-15\n",
      "EPOCH 149 COMPLETE | MEAN LOSS 4.445832590960208e-12\n",
      "EPOCH 150 COMPLETE | MEAN LOSS 6.637892457916905e-12\n",
      "EPOCH 151 COMPLETE | MEAN LOSS 1.5929679797466179e-12\n",
      "EPOCH 152 COMPLETE | MEAN LOSS 6.073563874053889e-13\n",
      "EPOCH 153 COMPLETE | MEAN LOSS 4.3582937259145634e-12\n",
      "EPOCH 154 COMPLETE | MEAN LOSS 3.469446951953614e-12\n",
      "EPOCH 155 COMPLETE | MEAN LOSS 1.524202986047385e-13\n",
      "EPOCH 156 COMPLETE | MEAN LOSS 1.4748757770632892e-12\n",
      "EPOCH 157 COMPLETE | MEAN LOSS 3.348397115132684e-12\n",
      "EPOCH 158 COMPLETE | MEAN LOSS 1.255671122635249e-12\n",
      "EPOCH 159 COMPLETE | MEAN LOSS 8.443246102274315e-14\n",
      "EPOCH 160 COMPLETE | MEAN LOSS 1.8508949928275343e-12\n",
      "EPOCH 161 COMPLETE | MEAN LOSS 1.9039791965269615e-12\n",
      "EPOCH 162 COMPLETE | MEAN LOSS 1.9192647471300006e-13\n",
      "EPOCH 163 COMPLETE | MEAN LOSS 5.115907697472721e-13\n",
      "EPOCH 164 COMPLETE | MEAN LOSS 1.5929679797466179e-12\n",
      "EPOCH 165 COMPLETE | MEAN LOSS 7.366907084360719e-13\n",
      "EPOCH 166 COMPLETE | MEAN LOSS 1.1193268534270827e-14\n",
      "EPOCH 167 COMPLETE | MEAN LOSS 8.208189683500677e-13\n",
      "EPOCH 168 COMPLETE | MEAN LOSS 9.78985781330266e-13\n",
      "EPOCH 169 COMPLETE | MEAN LOSS 1.2472023414034085e-13\n",
      "EPOCH 170 COMPLETE | MEAN LOSS 2.3022472817046944e-13\n",
      "EPOCH 171 COMPLETE | MEAN LOSS 7.834533022332835e-13\n",
      "EPOCH 172 COMPLETE | MEAN LOSS 3.7507996708541214e-13\n",
      "EPOCH 173 COMPLETE | MEAN LOSS 7.214229214014268e-15\n",
      "EPOCH 174 COMPLETE | MEAN LOSS 4.105604745063829e-13\n",
      "EPOCH 175 COMPLETE | MEAN LOSS 4.678057941021052e-13\n",
      "EPOCH 176 COMPLETE | MEAN LOSS 4.733102798581967e-14\n",
      "EPOCH 177 COMPLETE | MEAN LOSS 1.3111511876218174e-13\n",
      "EPOCH 178 COMPLETE | MEAN LOSS 3.7873926217457666e-13\n",
      "EPOCH 179 COMPLETE | MEAN LOSS 1.5475620784854983e-13\n",
      "EPOCH 180 COMPLETE | MEAN LOSS 1.057154364048074e-14\n",
      "EPOCH 181 COMPLETE | MEAN LOSS 2.231304030431147e-13\n",
      "EPOCH 182 COMPLETE | MEAN LOSS 2.1476376232953954e-13\n",
      "EPOCH 183 COMPLETE | MEAN LOSS 9.381384558082573e-15\n",
      "EPOCH 184 COMPLETE | MEAN LOSS 9.240608278560103e-14\n",
      "EPOCH 185 COMPLETE | MEAN LOSS 1.893241119432787e-13\n",
      "EPOCH 186 COMPLETE | MEAN LOSS 5.0628390368956387e-14\n",
      "EPOCH 187 COMPLETE | MEAN LOSS 1.6042722705833512e-14\n",
      "EPOCH 188 COMPLETE | MEAN LOSS 1.2683409877922714e-13\n",
      "EPOCH 189 COMPLETE | MEAN LOSS 8.100409232270067e-14\n",
      "EPOCH 190 COMPLETE | MEAN LOSS 1.9984014443252817e-17\n",
      "EPOCH 191 COMPLETE | MEAN LOSS 5.899503108253157e-14\n",
      "EPOCH 192 COMPLETE | MEAN LOSS 8.270939488852491e-14\n",
      "EPOCH 193 COMPLETE | MEAN LOSS 1.1832756996454918e-14\n",
      "EPOCH 194 COMPLETE | MEAN LOSS 2.0892176877396197e-14\n",
      "EPOCH 195 COMPLETE | MEAN LOSS 6.192601986754198e-14\n",
      "EPOCH 196 COMPLETE | MEAN LOSS 2.7853275241795927e-14\n",
      "EPOCH 197 COMPLETE | MEAN LOSS 2.566835632933362e-15\n",
      "EPOCH 198 COMPLETE | MEAN LOSS 4.106937012693379e-14\n",
      "EPOCH 199 COMPLETE | MEAN LOSS 3.414157845327281e-14\n",
      "EPOCH 200 COMPLETE | MEAN LOSS 4.3520742565306136e-16\n",
      "EPOCH 201 COMPLETE | MEAN LOSS 2.0892176877396197e-14\n",
      "EPOCH 202 COMPLETE | MEAN LOSS 3.091749078976136e-14\n",
      "EPOCH 203 COMPLETE | MEAN LOSS 4.6984638402136625e-15\n",
      "EPOCH 204 COMPLETE | MEAN LOSS 7.469580509678053e-15\n",
      "EPOCH 205 COMPLETE | MEAN LOSS 2.5421886817866833e-14\n",
      "EPOCH 206 COMPLETE | MEAN LOSS 7.993605777301127e-15\n",
      "EPOCH 207 COMPLETE | MEAN LOSS 1.9984014443252818e-15\n",
      "EPOCH 208 COMPLETE | MEAN LOSS 1.6042722705833512e-14\n",
      "EPOCH 209 COMPLETE | MEAN LOSS 1.0880185641326534e-14\n",
      "EPOCH 210 COMPLETE | MEAN LOSS 1.9984014443252817e-17\n",
      "EPOCH 211 COMPLETE | MEAN LOSS 7.993605777301127e-15\n",
      "EPOCH 212 COMPLETE | MEAN LOSS 9.672262990534364e-15\n",
      "EPOCH 213 COMPLETE | MEAN LOSS 7.194245199571015e-16\n",
      "EPOCH 214 COMPLETE | MEAN LOSS 3.9168668308775524e-15\n",
      "EPOCH 215 COMPLETE | MEAN LOSS 6.2372329523441294e-15\n",
      "EPOCH 216 COMPLETE | MEAN LOSS 1.0746958878371515e-15\n",
      "EPOCH 217 COMPLETE | MEAN LOSS 1.3877787807814457e-15\n",
      "EPOCH 218 COMPLETE | MEAN LOSS 3.732569808789776e-15\n",
      "EPOCH 219 COMPLETE | MEAN LOSS 1.7408297026122454e-15\n",
      "EPOCH 220 COMPLETE | MEAN LOSS 4.3520742565306136e-16\n",
      "EPOCH 221 COMPLETE | MEAN LOSS 2.418065747633591e-15\n",
      "EPOCH 222 COMPLETE | MEAN LOSS 1.7408297026122454e-15\n",
      "EPOCH 223 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 224 COMPLETE | MEAN LOSS 1.8673951274195133e-15\n",
      "EPOCH 225 COMPLETE | MEAN LOSS 1.8673951274195133e-15\n",
      "EPOCH 226 COMPLETE | MEAN LOSS 7.993605777301127e-17\n",
      "EPOCH 227 COMPLETE | MEAN LOSS 5.684341886080802e-16\n",
      "EPOCH 228 COMPLETE | MEAN LOSS 9.792167077193881e-16\n",
      "EPOCH 229 COMPLETE | MEAN LOSS 5.684341886080802e-16\n",
      "EPOCH 230 COMPLETE | MEAN LOSS 8.881784197001253e-18\n",
      "EPOCH 231 COMPLETE | MEAN LOSS 4.996003610813204e-16\n",
      "EPOCH 232 COMPLETE | MEAN LOSS 6.417089082333405e-16\n",
      "EPOCH 233 COMPLETE | MEAN LOSS 3.1974423109204507e-16\n",
      "EPOCH 234 COMPLETE | MEAN LOSS 1.9984014443252817e-17\n",
      "EPOCH 235 COMPLETE | MEAN LOSS 3.1974423109204507e-16\n",
      "EPOCH 236 COMPLETE | MEAN LOSS 3.1974423109204507e-16\n",
      "EPOCH 237 COMPLETE | MEAN LOSS 1.4210854715202004e-16\n",
      "EPOCH 238 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 239 COMPLETE | MEAN LOSS 1.7985612998927537e-16\n",
      "EPOCH 240 COMPLETE | MEAN LOSS 1.7985612998927537e-16\n",
      "EPOCH 241 COMPLETE | MEAN LOSS 1.7985612998927537e-16\n",
      "EPOCH 242 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 243 COMPLETE | MEAN LOSS 5.551115123125783e-17\n",
      "EPOCH 244 COMPLETE | MEAN LOSS 1.4210854715202004e-16\n",
      "EPOCH 245 COMPLETE | MEAN LOSS 1.4210854715202004e-16\n",
      "EPOCH 246 COMPLETE | MEAN LOSS 1.9984014443252817e-17\n",
      "EPOCH 247 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 248 COMPLETE | MEAN LOSS 1.4210854715202004e-16\n",
      "EPOCH 249 COMPLETE | MEAN LOSS 1.4210854715202004e-16\n",
      "EPOCH 250 COMPLETE | MEAN LOSS 1.9984014443252817e-17\n",
      "EPOCH 251 COMPLETE | MEAN LOSS 8.881784197001253e-18\n",
      "EPOCH 252 COMPLETE | MEAN LOSS 5.551115123125783e-17\n",
      "EPOCH 253 COMPLETE | MEAN LOSS 5.551115123125783e-17\n",
      "EPOCH 254 COMPLETE | MEAN LOSS 3.552713678800501e-17\n",
      "EPOCH 255 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 256 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 257 COMPLETE | MEAN LOSS 8.881784197001253e-18\n",
      "EPOCH 258 COMPLETE | MEAN LOSS 8.881784197001253e-18\n",
      "EPOCH 259 COMPLETE | MEAN LOSS 8.881784197001253e-18\n",
      "EPOCH 260 COMPLETE | MEAN LOSS 8.881784197001253e-18\n",
      "EPOCH 261 COMPLETE | MEAN LOSS 8.881784197001253e-18\n",
      "EPOCH 262 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 263 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 264 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 265 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 266 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 267 COMPLETE | MEAN LOSS 8.881784197001253e-18\n",
      "EPOCH 268 COMPLETE | MEAN LOSS 8.881784197001253e-18\n",
      "EPOCH 269 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 270 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 271 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 272 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 273 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 274 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 275 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 276 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 277 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 278 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 279 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 280 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 281 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 282 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 283 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 284 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 285 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 286 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 287 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 288 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 289 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 290 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 291 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 292 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 293 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 294 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 295 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 296 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 297 COMPLETE | MEAN LOSS 2.220446049250313e-18\n",
      "EPOCH 298 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 299 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 300 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 301 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 302 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 303 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 304 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 305 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 306 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 307 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 308 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 309 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 310 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 311 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 312 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 313 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 314 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 315 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 316 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 317 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 318 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 319 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 320 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 321 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 322 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 323 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 324 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 325 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 326 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 327 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 328 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 329 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 330 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 331 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 332 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 333 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 334 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 335 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 336 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 337 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 338 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 339 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 340 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 341 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 342 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 343 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 344 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 345 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 346 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 347 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 348 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 349 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 350 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 351 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 352 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 353 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 354 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 355 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 356 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 357 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 358 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 359 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 360 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 361 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 362 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 363 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 364 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 365 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 366 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 367 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 368 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 369 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 370 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 371 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 372 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 373 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 374 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 375 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 376 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 377 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 378 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 379 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 380 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 381 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 382 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 383 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 384 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 385 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 386 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 387 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 388 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 389 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 390 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 391 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 392 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 393 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 394 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 395 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 396 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 397 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 398 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 399 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 400 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 401 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 402 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 403 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 404 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 405 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 406 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 407 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 408 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 409 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 410 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 411 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 412 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 413 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 414 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 415 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 416 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 417 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 418 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 419 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 420 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 421 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 422 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 423 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 424 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 425 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 426 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 427 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 428 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 429 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 430 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 431 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 432 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 433 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 434 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 435 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 436 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 437 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 438 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 439 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 440 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 441 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 442 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 443 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 444 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 445 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 446 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 447 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 448 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 449 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 450 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 451 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 452 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 453 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 454 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 455 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 456 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 457 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 458 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 459 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 460 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 461 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 462 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 463 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 464 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 465 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 466 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 467 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 468 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 469 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 470 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 471 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 472 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 473 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 474 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 475 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 476 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 477 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 478 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 479 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 480 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 481 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 482 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 483 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 484 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 485 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 486 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 487 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 488 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 489 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 490 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 491 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 492 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 493 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 494 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 495 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 496 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 497 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 498 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 499 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 500 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 501 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 502 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 503 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 504 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 505 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 506 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 507 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 508 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 509 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 510 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 511 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 512 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 513 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 514 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 515 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 516 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 517 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 518 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 519 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 520 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 521 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 522 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 523 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 524 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 525 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 526 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 527 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 528 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 529 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 530 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 531 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 532 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 533 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 534 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 535 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 536 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 537 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 538 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 539 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 540 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 541 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 542 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 543 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 544 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 545 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 546 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 547 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 548 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 549 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 550 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 551 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 552 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 553 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 554 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 555 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 556 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 557 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 558 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 559 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 560 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 561 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 562 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 563 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 564 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 565 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 566 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 567 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 568 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 569 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 570 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 571 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 572 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 573 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 574 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 575 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 576 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 577 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 578 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 579 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 580 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 581 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 582 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 583 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 584 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 585 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 586 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 587 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 588 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 589 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 590 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 591 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 592 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 593 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 594 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 595 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 596 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 597 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 598 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 599 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 600 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 601 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 602 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 603 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 604 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 605 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 606 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 607 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 608 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 609 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 610 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 611 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 612 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 613 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 614 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 615 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 616 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 617 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 618 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 619 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 620 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 621 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 622 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 623 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 624 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 625 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 626 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 627 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 628 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 629 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 630 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 631 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 632 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 633 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 634 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 635 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 636 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 637 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 638 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 639 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 640 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 641 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 642 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 643 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 644 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 645 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 646 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 647 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 648 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 649 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 650 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 651 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 652 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 653 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 654 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 655 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 656 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 657 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 658 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 659 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 660 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 661 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 662 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 663 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 664 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 665 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 666 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 667 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 668 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 669 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 670 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 671 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 672 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 673 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 674 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 675 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 676 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 677 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 678 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 679 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 680 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 681 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 682 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 683 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 684 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 685 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 686 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 687 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 688 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 689 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 690 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 691 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 692 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 693 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 694 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 695 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 696 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 697 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 698 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 699 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 700 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 701 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 702 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 703 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 704 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 705 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 706 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 707 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 708 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 709 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 710 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 711 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 712 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 713 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 714 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 715 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 716 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 717 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 718 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 719 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 720 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 721 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 722 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 723 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 724 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 725 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 726 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 727 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 728 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 729 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 730 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 731 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 732 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 733 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 734 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 735 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 736 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 737 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 738 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 739 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 740 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 741 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 742 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 743 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 744 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 745 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 746 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 747 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 748 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 749 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 750 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 751 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 752 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 753 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 754 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 755 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 756 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 757 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 758 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 759 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 760 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 761 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 762 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 763 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 764 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 765 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 766 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 767 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 768 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 769 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 770 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 771 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 772 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 773 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 774 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 775 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 776 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 777 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 778 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 779 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 780 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 781 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 782 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 783 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 784 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 785 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 786 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 787 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 788 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 789 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 790 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 791 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 792 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 793 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 794 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 795 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 796 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 797 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 798 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 799 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 800 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 801 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 802 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 803 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 804 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 805 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 806 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 807 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 808 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 809 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 810 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 811 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 812 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 813 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 814 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 815 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 816 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 817 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 818 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 819 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 820 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 821 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 822 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 823 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 824 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 825 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 826 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 827 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 828 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 829 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 830 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 831 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 832 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 833 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 834 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 835 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 836 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 837 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 838 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 839 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 840 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 841 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 842 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 843 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 844 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 845 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 846 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 847 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 848 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 849 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 850 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 851 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 852 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 853 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 854 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 855 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 856 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 857 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 858 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 859 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 860 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 861 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 862 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 863 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 864 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 865 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 866 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 867 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 868 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 869 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 870 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 871 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 872 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 873 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 874 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 875 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 876 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 877 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 878 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 879 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 880 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 881 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 882 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 883 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 884 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 885 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 886 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 887 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 888 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 889 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 890 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 891 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 892 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 893 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 894 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 895 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 896 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 897 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 898 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 899 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 900 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 901 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 902 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 903 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 904 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 905 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 906 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 907 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 908 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 909 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 910 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 911 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 912 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 913 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 914 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 915 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 916 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 917 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 918 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 919 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 920 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 921 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 922 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 923 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 924 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 925 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 926 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 927 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 928 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 929 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 930 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 931 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 932 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 933 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 934 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 935 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 936 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 937 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 938 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 939 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 940 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 941 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 942 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 943 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 944 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 945 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 946 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 947 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 948 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 949 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 950 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 951 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 952 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 953 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 954 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 955 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 956 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 957 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 958 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 959 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 960 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 961 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 962 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 963 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 964 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 965 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 966 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 967 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 968 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 969 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 970 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 971 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 972 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 973 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 974 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 975 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 976 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 977 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 978 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 979 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 980 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 981 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 982 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 983 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 984 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 985 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 986 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 987 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 988 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 989 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 990 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 991 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 992 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 993 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 994 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 995 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 996 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 997 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 998 COMPLETE | MEAN LOSS 0.0\n",
      "EPOCH 999 COMPLETE | MEAN LOSS 0.0\n"
     ]
    }
   ],
   "source": [
    "model = EVGNN()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.MSELoss()\n",
    "losses = []\n",
    "predictions = []\n",
    "targets = []\n",
    "epochs = range(1000)\n",
    "\n",
    "# training loop\n",
    "model.train()\n",
    "for epoch in epochs:\n",
    "    epoch_mean_loss = 0\n",
    "    for data in molecules_dataset[:1]:\n",
    "        U_hat = model(data)\n",
    "        predictions.append(U_hat.item())\n",
    "        U = data.y\n",
    "        targets.append(U)\n",
    "        loss = loss_fn(U_hat, U)\n",
    "        losses.append(loss.item())\n",
    "        epoch_mean_loss += loss.item()\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    epoch_mean_loss /= len(molecules_dataset)\n",
    "    print(f'EPOCH {epoch} COMPLETE | MEAN LOSS {epoch_mean_loss}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xs = [x for x in range(len(losses))]\n",
    "\n",
    "# plt.plot(xs, losses)\n",
    "plt.plot(xs, losses)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14233839511871338\n",
      "0.14233839511871338\n"
     ]
    }
   ],
   "source": [
    "item_num = 0\n",
    "print(model(molecules_dataset[item_num]).item())\n",
    "print(molecules_dataset[item_num].y.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeometricDL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
