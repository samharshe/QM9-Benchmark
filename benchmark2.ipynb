{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I will get this model to work today.\n",
    "today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from itertools import product\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric as tg\n",
    "from torch import Tensor, LongTensor\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance(pos1: Tensor, pos2: Tensor) -> float:\n",
    "    return torch.sum(torch.pow(torch.sub(pos1, pos2), 2)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features_df = pd.read_csv('baby_QM9/raw/node_attributes.txt', header=None)\n",
    "node_features = torch.tensor(node_features_df.values)\n",
    "graph_features_df = pd.read_csv('baby_QM9/raw/Y.txt', header=None)\n",
    "graph_features = torch.tensor(graph_features_df.values)\n",
    "atomic_numbers = node_features[:,5].long()\n",
    "positions = node_features[:,-3:]\n",
    "atomization_energies = graph_features[:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_graph_node_indices = [0]\n",
    "node_indicators_df = pd.read_csv('baby_QM9/raw/graph_indicator.txt', header=None)\n",
    "node_indicators = torch.tensor(node_indicators_df.values)\n",
    "for ix in range(len(node_indicators))[1:]:\n",
    "    if node_indicators[ix] != node_indicators[ix-1]:\n",
    "        new_graph_node_indices.append(ix)\n",
    "new_graph_node_indices.append(len(node_indicators))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_complete_edge_index(n: int) -> LongTensor:\n",
    "    edges = list(filter(lambda e: e[0] != e[1], product(range(n), range(n))))\n",
    "    return torch.tensor(edges, dtype=torch.long).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_edge_distance_tensor(positions: Tensor) -> Tensor:\n",
    "    edge_distance_tensor = torch.zeros(positions.size()[0], positions.size()[0])\n",
    "    for ix, source_position in enumerate(positions):\n",
    "        for jx, destination_position in enumerate(positions):\n",
    "            edge_distance_tensor[ix][jx] = compute_distance(source_position, destination_position)\n",
    "    return edge_distance_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "molecules = []\n",
    "for start, end in zip(new_graph_node_indices, new_graph_node_indices[1:]):\n",
    "    x = atomic_numbers.clone()[start:end].view(-1, 1)\n",
    "    edge_index = make_complete_edge_index(end-start)\n",
    "    y = atomization_energies.clone()[start:end].view(-1, 1)\n",
    "    pos = positions.clone()[start:end]\n",
    "    edge_distances = make_edge_distance_tensor(pos)\n",
    "    molecule = Data(x = x, edge_index = edge_index, y = y, pos = pos, edge_distances = edge_distances)\n",
    "    molecules.append(molecule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoleculesDataset(Dataset):\n",
    "    def __init__(self, data: List[Data]) -> None:\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        \n",
    "    def len(self) -> int:\n",
    "        return len(self.data)\n",
    "    \n",
    "    def get(self, idx: int) -> Data:\n",
    "        return self.data[idx]\n",
    "\n",
    "dataset = MoleculesDataset(molecules)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EVMPLayer(nn.Module):\n",
    "    def __init__(self, embed_dim: int) -> None:\n",
    "        super(EVMPLayer, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.act = nn.ReLU()\n",
    "        message_input_size = 2 * embed_dim + 1\n",
    "        \n",
    "        # take in a message tensor of size 2 * embed_dim + 1 and get out a new h_i of size embed_dim\n",
    "        self.message_mlp = nn.Sequential(nn.Linear(message_input_size, embed_dim), self.act)\n",
    "        \n",
    "        # take in a message tensor of size embed_dim and an original h_i of size embed_dim and get out a new h_i of size embed_dim\n",
    "        self.node_update_mlp = nn.Sequential(nn.Linear(2 * embed_dim, embed_dim), self.act)\n",
    "                \n",
    "    def make_message(self, source_tensor: int, target_tensor: int, distance: float) -> Tensor:\n",
    "        message_tensor = torch.cat((source_tensor.view(-1), target_tensor.view(-1), torch.Tensor([distance])), dim=0)\n",
    "        return self.message_mlp(message_tensor)\n",
    "    \n",
    "    def update_node(self, node_tensor: Tensor, message_tensor: Tensor) -> Tensor:\n",
    "        combined_tensor = torch.cat((node_tensor, message_tensor), dim=0).view(1,64)\n",
    "        return self.node_update_mlp(combined_tensor)\n",
    "    \n",
    "    def forward(self, embed_tensor: Tensor, edge_distances: Tensor) -> Tensor:\n",
    "        new_embed_tensor = torch.zeros_like(embed_tensor)\n",
    "        # for each molecule in the dataset\n",
    "        for ix, source in enumerate(embed_tensor):\n",
    "            # create a tensor that tracks the sum of the messages\n",
    "            message_sum = torch.zeros_like(source)\n",
    "            # for each other molecule in the dataset\n",
    "            for jx, target in enumerate(embed_tensor):\n",
    "                if ix != jx:\n",
    "                    # add the message tensor between them to the sum tensor\n",
    "                    message_sum += self.make_message(source, target, edge_distances[ix,jx].item())\n",
    "            # update the tensor that keeps track of all molecule embeddings by making its row ix the new embedding of the molecule\n",
    "            new_embed_tensor[ix] = self.update_node(source, message_sum)\n",
    "        \n",
    "        return new_embed_tensor\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RowWiseFCL(nn.Module): \n",
    "    def __init__(self, in_dim: int, out_dim: int) -> None: \n",
    "        super(RowWiseFCL, self).__init__() \n",
    "        self.out_dim = out_dim\n",
    "        self.row_layer = nn.Sequential(nn.Linear(in_dim, out_dim), nn.ReLU())\n",
    "      \n",
    "    def forward(self, in_tensor) -> Tensor:\n",
    "        out_tensor = torch.zeros(in_tensor.size()[0], self.out_dim)\n",
    "        print('in_tensor', in_tensor.size())\n",
    "        print('out_dim', self.out_dim)\n",
    "        print('out_tensor', out_tensor.size())\n",
    "        for ix, row in enumerate(in_tensor):\n",
    "            out_tensor[ix] = self.row_layer(row)\n",
    "        return out_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EVGNN(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(EVGNN, self).__init__()\n",
    "        \n",
    "        loss_function = nn.MSELoss()\n",
    "        \n",
    "        self.embedding = nn.Embedding(118, 32)\n",
    "        self.mp1 = EVMPLayer(32)\n",
    "        self.mp2 = EVMPLayer(32)\n",
    "        self.prediction1 = RowWiseFCL(32, 8) \n",
    "        self.prediction2 = RowWiseFCL(8, 1)\n",
    "\n",
    "    def forward(self, data = Data) -> float:\n",
    "        x = self.embedding(data['x'])\n",
    "        x = F.normalize(x, p=1, dim=1)\n",
    "        x = self.mp1(x, data.edge_distances)\n",
    "        x = F.normalize(x, p=1, dim=1)\n",
    "        x = self.mp2(x, data.edge_distances)\n",
    "        x = F.normalize(x, p=1, dim=1)\n",
    "        x = self.prediction1(x)\n",
    "        x = self.prediction2(x)\n",
    "        U_hat = torch.sum(x)\n",
    "        \n",
    "        return U_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(pred: float, target: float) -> float:\n",
    "    return torch.mean((pred - target) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[322], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# training loop\u001b[39;00m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata_loader\u001b[49m:\n\u001b[1;32m      7\u001b[0m     U_hat \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m      8\u001b[0m     U \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39my\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_loader' is not defined"
     ]
    }
   ],
   "source": [
    "model = EVGNN()\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# training loop\n",
    "model.train()\n",
    "for data in data_loader:\n",
    "    U_hat = model(data)\n",
    "    U = data.y\n",
    "    loss = criterion(U_hat, U)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    \n",
    "model.eval()\n",
    "for data in loader:\n",
    "    pred = model(data)\n",
    "    target = data.y\n",
    "    preds.append(pred)\n",
    "    targets.append(target)\n",
    "    test_mae += total_absolute_error(pred, target).item()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeometricDL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
